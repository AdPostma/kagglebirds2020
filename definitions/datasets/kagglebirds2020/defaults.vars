# the dataset will consist of all audio files found in a particular directory
# tree; for training and validation, it will be limited to those occurring in
# one of the training csv files, split according to a particular scheme

# directory of audio files, can be absolute or relative to this config file
data.audio_dir=audio
# regular expression for selecting audio files to consider (acts on full path)
data.audio_regexp=.*\.wav
# official training csv
data.train_csv=train.csv
# additional training csvs, optional, separated by colons (:)
data.extra_csvs=train_extended.csv
# train/validation split: stratified or byrecordist
data.split_mode=byrecordist
data.split_seed=1
data.valid_size=4000
# filter by minimum quality rating (between 0 and 5)
data.min_rating_train=0
data.min_rating_valid=0

# foreground and background labels are combined to "label_all" with weights:
data.label_fg_weight=1
data.label_bg_weight=1

# class-based sampling: equal, roundrobin, or a comma-separated list of weights
data.class_sample_weights=

# downmixing to mono: average, random_uniform or none
data.downmix=average

# input block length (in seconds, set both to 0 to use full recordings)
data.len_min=30
data.len_max=30
# number of buckets between min and max length for bucketed mini-batches
data.len_buckets=10

# mix in background noise from a separate source of annotated data
# how probable it is for an example to be mixed with background noise
data.mix_background_noise.probability=0
# if mixed, what is the allowed range for the proportion of background noise
data.mix_background_noise.min_factor=0
data.mix_background_noise.max_factor=0.5
# how probable it is for an example to only consist of background noise
data.mix_background_noise.noise_only_probability=0
# which labels to set to zero for examples consisting of noise only
data.mix_background_noise.noise_only_zero_labels=label_bg,label_all
# audio source directory and regexp
# (targets are expected to be found by replacing the file extension with .csv)
data.mix_background_noise.audio_dir=audio/noise
data.mix_background_noise.audio_regexp=.*\.wav

# mix in synthetic (colored / Gaussian (1/f)**beta / power law) noise
# how probable it is for an example to be mixed with synthetic noise
data.mix_synthetic_noise.probability=0
# if mixed, what is the allowed range for the proportion of synthetic noise
data.mix_synthetic_noise.min_factor=0.01
data.mix_synthetic_noise.max_factor=0.05
# range of noise (colors) to sample from
# (0: white noise. 1: pink noise, 2: brown noise)
data.mix_synthetic_noise.min_beta=0
data.mix_synthetic_noise.max_beta=2
# number of synthetic noise waveform samples to pre-compute for the augmantation
# (with colors of samples linearly spanning interval [min_beta: max_beta])
data.mix_synthetic_noise.num_samples=64

# apply mixup (interpolation between pairs of examples) to the following keys
# separated by commas (e.g., "input,label_bg,label_all")
data.mixup.apply_to=
# concentration (the smaller, the less likely they'll be mixed in equal parts)
data.mixup.alpha=0.3
# whether and which keys to re-binarize after mixing them
data.mixup.binarize=
